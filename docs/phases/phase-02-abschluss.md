# Phase 2: K3s HA-Cluster Installation - Abschlussdokument

**Status:** âœ… Abgeschlossen  
**Abgeschlossen am:** 09.02.2026  
**Dauer:** 1 Tag  
**Umgebung:** DEV (k8s-dev-21, k8s-dev-22, k8s-dev-23)

---

## Zusammenfassung

Phase 2 wurde erfolgreich abgeschlossen. Ein vollstÃ¤ndig funktionsfÃ¤higer K3s High-Availability-Cluster mit 3 Control-Plane-Nodes lÃ¤uft in der DEV-Umgebung. Die Installation erfolgt vollstÃ¤ndig automatisiert Ã¼ber Ansible mit festen Versionsnummern fÃ¼r maximale Reproduzierbarkeit.

---

## Erreichte Ziele

### Infrastruktur
- âœ… **K3s HA-Cluster:** 3 Control-Plane Nodes mit embedded etcd
- âœ… **Version:** K3s v1.35.0+k3s3 (Kubernetes 1.35)
- âœ… **Nodes:** Alle Ready, vollstÃ¤ndig funktionsfÃ¤hig
- âœ… **Netzwerk:** Calico CNI aktiv und funktionsfÃ¤hig
- âœ… **Core Services:** CoreDNS und metrics-server laufen

### Automatisierung
- âœ… **Ansible-Playbooks:** VollstÃ¤ndig funktionsfÃ¤hige Installation
- âœ… **SSH-Key-Management:** 4 Workstations autorisiert
- âœ… **Versions-Management:** Feste Versionen statt Channels
- âœ… **Upgrade-FÃ¤higkeit:** Automatische Versionserkennung implementiert
- âœ… **Idempotenz:** Playbooks kÃ¶nnen mehrfach ausgefÃ¼hrt werden

### Dokumentation
- âœ… **README.md:** VollstÃ¤ndige Ansible-Nutzungsanleitung
- âœ… **SSH-KEYS.md:** Quick Reference fÃ¼r SSH-Key-Management
- âœ… **SSH-KEY-MANAGEMENT.md:** Umfassende Dokumentation aller SSH-Prozesse

---

## Technische Details

### Cluster-Konfiguration

**Nodes:**
```
NAME         STATUS   ROLES                  AGE     VERSION
k8s-dev-21   Ready    control-plane,etcd     Active  v1.35.0+k3s3
k8s-dev-22   Ready    control-plane,etcd     Active  v1.35.0+k3s3
k8s-dev-23   Ready    control-plane,etcd     Active  v1.35.0+k3s3
```

**IP-Adressen:**
- k8s-dev-21: 192.168.180.21
- k8s-dev-22: 192.168.180.22
- k8s-dev-23: 192.168.180.23

**Deaktivierte Komponenten (fÃ¼r GitOps):**
- Traefik (wird in Phase 4 manuell installiert)
- ServiceLB (wird durch MetalLB ersetzt)
- Local-Storage (wird durch Longhorn ersetzt)

### Ansible-Struktur

```
ansible/
â”œâ”€â”€ ansible.cfg              # Ansible 2.20+ kompatibel
â”œâ”€â”€ README.md                # Nutzungsanleitung
â”œâ”€â”€ SSH-KEYS.md              # Quick Reference
â”œâ”€â”€ inventory/
â”‚   â””â”€â”€ dev/
â”‚       â”œâ”€â”€ hosts.ini        # Inventory (3 Nodes, 2 Gruppen)
â”‚       â””â”€â”€ group_vars/
â”‚           â”œâ”€â”€ all.yml      # K3s-Konfiguration
â”‚           â”œâ”€â”€ secrets.yml  # SSH-Keys + Token (local only)
â”‚           â””â”€â”€ secrets.example.yml
â”œâ”€â”€ playbooks/
â”‚   â”œâ”€â”€ 01-setup-ssh-keys.yml    # SSH-Key-Distribution
â”‚   â””â”€â”€ 02-install-k3s.yml       # K3s HA-Installation
â”œâ”€â”€ roles/
â”‚   â”œâ”€â”€ common/              # System-Vorbereitung
â”‚   â””â”€â”€ k3s/                 # K3s-Installation
â””â”€â”€ templates/
    â”œâ”€â”€ authorized_keys.j2   # SSH-Keys
    â””â”€â”€ k3s-config.yaml.j2   # K3s-Konfiguration
```

### kubeconfig

**Speicherort:** `~/git/eneg-k8s-infrastructure-v2/kubeconfig-dev.yaml`

**Verwendung:**
```bash
export KUBECONFIG=~/git/eneg-k8s-infrastructure-v2/kubeconfig-dev.yaml
kubectl get nodes
```

---

## Wichtige Learnings

### 1. K3s Token-Format (KRITISCH!)

**Problem:** K3s verwendet zwei verschiedene Token-Formate:
- **Einfaches Password:** FÃ¼r ersten Server (64 Zeichen alphanumerisch)
- **K10-Format:** FÃ¼r zusÃ¤tzliche Server (aus `/var/lib/rancher/k3s/server/node-token`)

**LÃ¶sung:**
```yaml
# First Server - einfaches Password
generated_k3s_token: "{{ lookup('password', '/dev/null chars=ascii_letters,digits length=64') }}"

# Additional Servers - K10 Token vom First Server
K3S_TOKEN={{ hostvars[groups['k3s_initial_server'][0]]['k3s_cluster_token'] }}
```

**Dokumentation:** https://docs.k3s.io/cli/token#token-format

### 2. Version Pinning statt Channels

**Problem:** K3s-Channels (`stable`, `latest`) kÃ¶nnen zu unerwarteten Upgrades fÃ¼hren.

**LÃ¶sung:** Feste Versionsnummern verwenden:
```yaml
k3s_version: "v1.35.0+k3s3"  # Fest gepinnt
# k3s_channel wird nicht mehr verwendet
```

**Installationsskript:**
```bash
INSTALL_K3S_VERSION={{ k3s_version }}  # Statt INSTALL_K3S_CHANNEL
```

### 3. Upgrade-Erkennung

**Problem:** `creates: /usr/local/bin/k3s` verhindert Upgrades.

**LÃ¶sung:** Installierte Version prÃ¼fen und vergleichen:
```yaml
- name: Installierte K3s Version prÃ¼fen
  ansible.builtin.shell: |
    if [ -f /usr/local/bin/k3s ]; then
      /usr/local/bin/k3s --version | head -n1 | awk '{print $3}'
    else
      echo "not_installed"
    fi
  register: k3s_current_version
  changed_when: false

- name: K3s installieren/upgraden
  when: k3s_current_version.stdout != k3s_version
  ...
```

### 4. Token-Konflikt bei Upgrades

**Problem:** Upgrade von v1.34.3 â†’ v1.35.0 mit neuem Token fÃ¼hrte zu:
```
failed to reconcile with local datastore: bootstrap data already found 
and encrypted with different token
```

**Root Cause:** etcd-Datenbank war mit altem Token verschlÃ¼sselt.

**LÃ¶sung:** Bei Major-Upgrades oder Token-Ã„nderungen:
- Cluster deinstallieren: `/usr/local/bin/k3s-uninstall.sh`
- Frische Installation mit neuem Token

**PrÃ¤ventiv:** Token niemals Ã¤ndern bei laufendem Cluster!

### 5. Ansible 2.20+ Callback-Plugin

**Problem:** `community.general.yaml callback plugin has been removed`

**LÃ¶sung:** `ansible.cfg` anpassen:
```ini
[defaults]
stdout_callback = default
result_format = yaml  # Statt stdout_callback = yaml
```

### 6. Username auf Nodes

**Wichtig:** Der SSH-Username ist **`admin-ubuntu`**, NICHT `k8sadmin`.

Dies gilt fÃ¼r:
- SSH-Zugriff
- Ansible `remote_user`
- kubeconfig-Erstellung

---

## Troubleshooting-Erfahrungen

### Problem: K3s Service startet nicht nach Installation

**Symptom:**
```
Job for k3s.service failed because the control process exited with error code.
```

**Diagnose:**
```bash
sudo journalctl -u k3s -n 50 --no-pager
```

**HÃ¤ufige Ursachen:**
1. Token-Format falsch
2. Fehlende Kernel-Module
3. etcd-Datenbank-Probleme
4. Port 6443 bereits belegt

### Problem: Upgrade schlÃ¤gt fehl

**LÃ¶sung:** Clean Reinstall bei Token-Ã„nderungen:
```bash
# Auf allen Nodes
sudo /usr/local/bin/k3s-uninstall.sh

# Neu installieren
ansible-playbook -i inventory/dev/hosts.ini playbooks/02-install-k3s.yml
```

---

## Verwendete Versionen

| Komponente | Version | Hinweis |
|------------|---------|---------|
| K3s | v1.35.0+k3s3 | Fest gepinnt |
| Kubernetes | 1.35 | In K3s enthalten |
| Containerd | 2.1.5-k3s1 | In K3s enthalten |
| Ubuntu | 24.04.3 LTS | Kernel 6.8.0-71 |
| Ansible | 2.20.2 (core) | Auf k8s-mgmt-10 |
| kubectl | 1.35.0 | Auf k8s-mgmt-10 |

---

## NÃ¤chste Schritte (Phase 3)

**Phase 3: GitOps-Fundament**

Folgende Komponenten werden in Phase 3 installiert:
- [ ] ArgoCD fÃ¼r GitOps-Deployments
- [ ] SOPS + Age fÃ¼r Secret-VerschlÃ¼sselung
- [ ] GitHub Repository-Integration
- [ ] Base-Struktur fÃ¼r Kubernetes-Manifests

**Vorbereitung:**
- âœ… K3s-Cluster lÃ¤uft stabil
- âœ… kubectl-Zugriff funktioniert
- âœ… Git-Repository vorhanden
- âœ… SSH-Keys fÃ¼r GitHub Deploy-Key bereit

---

## Wichtige Dateien und Pfade

### Auf Management-VM (k8s-mgmt-10)

**Repository:**
```
~/git/eneg-k8s-infrastructure-v2/
```

**kubeconfig:**
```
~/git/eneg-k8s-infrastructure-v2/kubeconfig-dev.yaml
```

**Ansible:**
```
~/git/eneg-k8s-infrastructure-v2/ansible/
```

### Auf K8s-Nodes

**K3s Binary:**
```
/usr/local/bin/k3s
```

**K3s Service:**
```
/etc/systemd/system/k3s.service
```

**K3s Daten:**
```
/var/lib/rancher/k3s/
```

**K3s Konfiguration:**
```
/etc/rancher/k3s/config.yaml
```

**Token (nur first server):**
```
/var/lib/rancher/k3s/server/node-token
```

---

## Kommandos Cheat Sheet

### Cluster-Status

```bash
# Nodes anzeigen
kubectl get nodes -o wide

# Pods aller Namespaces
kubectl get pods -A

# Cluster-Info
kubectl cluster-info

# K3s Version auf Node
ssh admin-ubuntu@192.168.180.21 '/usr/local/bin/k3s --version'
```

### Ansible

```bash
# SSH-Keys verteilen (einmalig)
cd ~/git/eneg-k8s-infrastructure-v2/ansible
ansible-playbook -i inventory/dev/hosts.ini playbooks/01-setup-ssh-keys.yml --ask-pass

# K3s installieren/upgraden
ansible-playbook -i inventory/dev/hosts.ini playbooks/02-install-k3s.yml

# Node-Erreichbarkeit testen
ansible -i inventory/dev/hosts.ini all -m ping
```

### K3s Service

```bash
# Status prÃ¼fen
ssh admin-ubuntu@192.168.180.21 'sudo systemctl status k3s'

# Logs anzeigen
ssh admin-ubuntu@192.168.180.21 'sudo journalctl -u k3s -f'

# Service neu starten
ssh admin-ubuntu@192.168.180.21 'sudo systemctl restart k3s'

# Deinstallieren
ssh admin-ubuntu@192.168.180.21 'sudo /usr/local/bin/k3s-uninstall.sh'
```

---

## Git Commits (Phase 2)

Alle Ã„nderungen wurden sauber committed und gepusht:

1. `46fb3d9` - Fix Ansible 2.20+ callback plugin configuration
2. `619a849` - Fix K3s token format (single colon)
3. `b70ef86` - Fix K3s token format (simple password for first server)
4. `eac8ab2` - Fix inventory group name (k3s_initial_server)
5. `b1a7365` - Fix additional servers token (use K10 from first server)
6. `e6239c2` - Fix token hostvars delegation
7. `74d5012` - Change K3s channel from stable to latest for K8s 1.35+
8. `fd0b4a2` - Pin K3s to version v1.35.0+k3s3
9. `89e3e8b` - Enable K3s upgrades by checking installed version

**Dokumentation:**
- `ansible/README.md` - VollstÃ¤ndige Nutzungsanleitung
- `ansible/SSH-KEYS.md` - Quick Reference
- `docs/SSH-KEY-MANAGEMENT.md` - Umfassende SSH-Dokumentation

---

## Lessons Learned Summary

**DO:**
- âœ… Feste Versionen verwenden (kein `latest` oder `stable`)
- âœ… Token niemals bei laufendem Cluster Ã¤ndern
- âœ… Ansible-Playbooks idempotent gestalten
- âœ… Upgrade-Logik implementieren (Versions-Vergleich)
- âœ… Umfassende Dokumentation schreiben
- âœ… Learnings direkt dokumentieren (nicht spÃ¤ter!)

**DON'T:**
- âŒ Token-Format verwechseln (Simple vs. K10)
- âŒ `creates` fÃ¼r Upgrades verwenden
- âŒ Upgrades ohne Token-PrÃ¼fung durchfÃ¼hren
- âŒ Channels ohne Version-Pinning nutzen
- âŒ SSH-Username vergessen (admin-ubuntu!)

---

**Ende Phase 2 - Bereit fÃ¼r Phase 3!** ğŸš€
